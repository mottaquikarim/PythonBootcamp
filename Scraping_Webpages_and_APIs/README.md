# Scraping Webpages and APIs

Here we will apply what we have learned about the basics of python to do more useful things in terms of data accumulation. Specifically, we will look into how we can harvest data that might be useful for processing from online sources: webpages and publicly available APIs.


## Rules of Engagement
For all exercises, partner with someone next to you. Coding is **collaborating**. Talk through each problem and attempt to arrive at the solution **together**. Remember, it's ok to break stuff and get things wrong, that's the **only** way to learn!


## THEME: Automating Life

ğŸ‰ğŸˆğŸ‚ğŸ¾ğŸŠğŸ»ğŸ’ƒ

We are superpowered pythonic humans! Let's use our powers for good/evil! In this unit, we will look at how we can make our lives easier by gathering data freely available on websites in a structured and repeatable manner.

### [MTA Status Quo](MTA_Status_Quo/README.md)

ğŸš‡ âœ‹ ğŸ›‘ ğŸ–•ğŸ–• 

Or, which lines are fucked today?

#### [1. GET MTA Homepage Programmatically](MTA_Status_Quo/GET%20MTA%20Homepage%20Programmatically.md)
#### [2. Parse HTML and Search](MTA_Status_Quo/Parse%20HTML%20and%20Search.md)
#### [3. Isolate Subway Status Data](MTA_Status_Quo/Isolate%20Subway%20Status%20Data.md)
#### [4. Tfrom Status Data to Dict](MTA_Status_Quo/Tfrom%20Status%20Data%20to%20Dict.md)
#### [5. Filter Status by Line](MTA_Status_Quo/Filter%20Status%20by%20Line.md)
#### [6. Configure IFTTT to Send Alert](MTA_Status_Quo/Configure%20IFTTT%20to%20Send%20Alert.md)

## ğŸš— Parking Lot

Just some interesting/useful links I found while prepping for this class...
